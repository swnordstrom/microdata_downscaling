library(PMEDMrcpp)
library(ggplot2)
library(ipumsr)
library(dplyr)
library(tidyr)
library(purrr)

# Clear namespace
rm(list = ls())

# -------------------------------------------------------------------
# Setup

### Read in PUMS data

# Read in ACS PUMA (five year sample)
anc.lng.ddi = read_ipums_ddi('oregon_oha/01_data_inputs/usa_00044.xml')

# Read in separate ACS (same years) with disability+age
dis.age.ddi = read_ipums_ddi('oregon_oha/01_data_inputs/usa_00047.xml')

# Make PUMS data frame for ancestry+lang and subset to OR + Clark WA
anc.lng.pums = anc.lng.ddi %>%
  # Read in data
  read_ipums_micro() %>%
  # Subset to Oregon + Clark County WA
  filter(STATEFIP %in% 41 | PUMA %in% c(11101:11104, 21101:21104))

# Read in PUMS data frame for disablity + age and subset
dis.age.pums = dis.age.ddi %>%
  # Read in data
  read_ipums_micro() %>%
  # Subset to Oregon + Clark County WA
  filter(STATEFIP %in% 41 | PUMA %in% c(11101:11104, 21101:21104))

### Read in tabular data for controls
# Ancestry + language
anc.lng.tab.raw = read_nhgis('oregon_oha/01_data_inputs/nhgis0026_csv.zip', file_select = 2) %>%
  filter(STATEA %in% '41' | (STATEA %in% '53' & COUNTYA %in% '011'))
# Disability + age
dis.age.tab.raw = read_nhgis('oregon_oha/01_data_inputs/nhgis0028_csv.zip') %>%
  filter(STATEA %in% '41' | (STATEA %in% '53' & COUNTYA %in% '011'))
# Race + ethnicity (alone or in combination for each)
rac.eth.tab.raw = read_nhgis('oregon_oha/01_data_inputs/nhgis0029_csv.zip') %>%
  filter(STATEA %in% '41' | (STATEA %in% '53' & COUNTYA %in% '011'))
# Household counts
hh.tab.raw = read_nhgis('oregon_oha/01_data_inputs/nhgis0030_csv.zip', file_select = 1) %>%
  filter(STATEA %in% '41' | (STATEA %in% '53' & COUNTYA %in% '011'))

### Read in sums+moes for ancestry groups
ancestrs = read.csv('oregon_oha/01_data_inputs/variance_tables/orwa_county_ancestry-reald_sum_moe.csv')

### Read in megapuma key
megapumas = read.csv('oregon_oha/01_data_inputs/orwa_county_megapuma_2010-2020.csv')

### Extra language control table (generated by PRC for OHA)
oha.langc = read.csv('oregon_oha/01_data_inputs/results_lang_2023.csv')

### OHA language crosswalk
oha.langx = read.csv('oregon_oha/01_data_inputs/prc_langxwalk_langoha.csv')

### PUMS serial numbers with RELD assigned
pums.reld = read.csv('oregon_oha/01_data_inputs/5acs23_orwa_reldpri.csv')

# -------------------------------------------------------------------
# Combining files

### Combine ACS PUMA
acs.pums = merge(
  # Ancestry + language + race + ethnicity
  anc.lng.pums %>% 
    select(
      CBSERIAL, PERNUM, PERWT, HHWT, STATEFIP, PUMA, 
      contains('ANCESTR'), matches('RAC[^E]'), HISPAN,
      contains('LANG'), SPEAKENG
    ),
  dis.age.pums %>% 
    select(
      CBSERIAL, PERNUM, PERWT, HHWT, STATEFIP, PUMA, 
      contains('DIFF'), SEX, AGE, OCC, GQ
    )
) %>%
  # Merge to get megapumas
  merge(
    y = megapumas %>% distinct(STATE, PUMA, megapuma),
    by.x = c('STATEFIP', 'PUMA'), by.y = c('STATE', 'PUMA'),
  )

head(acs.pums)
nrow(acs.pums)
# should be zero
sum(is.na(acs.pums$megapuma))

### Assign megapumas to ACS tables
acs.tab = merge(
  x = anc.lng.tab.raw %>% 
    select(STATEA, COUNTYA, matches('[A-Za-z0-9]{4}[ME]\\d{3}')) %>%
    mutate(across(c(STATEA, COUNTYA), as.numeric)),
  y = dis.age.tab.raw %>% 
    select(STATEA, COUNTYA, matches('[A-Za-z0-9]{4}[ME]\\d{3}')) %>%
    mutate(across(c(STATEA, COUNTYA), as.numeric))
) %>%
  merge(
    y = rac.eth.tab.raw %>%
      select(STATEA, COUNTYA, matches('[A-Za-z0-9]{4}[ME]\\d{3}')) %>%
      mutate(across(c(STATEA, COUNTYA), as.numeric))
  ) %>%
  merge(
    y = megapumas %>% filter(time %in% 2020) %>% distinct(STATE, COUNTY, megapuma),
    by.x = c('STATEA', 'COUNTYA'), by.y = c('STATE', 'COUNTY')
  )

nrow(acs.tab)
ncol(acs.tab) # that's a lot.

### Assign megapumas to ancestry table
ances.table = merge(
  ancestrs %>%
    select(-c(NAME, variance, stderror)) %>%
    mutate(GEOID = gsub('\\d+US', '', GEOID)) %>%
    separate_wider_position(GEOID, widths = c(STATE = 2, COUNTY = 3)) %>%
    mutate(across(c(STATE, COUNTY), as.numeric)),
  megapumas %>% filter(time %in% 2020) %>% distinct(STATE, COUNTY, megapuma)
) %>%
  # Change 'other groups' to 'other.groups' (for alphabetizing)
  mutate(reald.grp = ifelse(reald.grp %in% 'Other groups', 'other.groups', reald.grp))

### Create a mergeable crosswalk for extra language info

# # First get languages (plus numeric codes, which we will merge by) from PUMS

# Extract the detailed language codes from the PUMS
acs.langs = ipums_val_labels(anc.lng.pums, var = 'LANGUAGED') %>%
  # Merge with those seen in the PUMS to cut down the number we need to reconcile
  merge(y = distinct(anc.lng.pums, LANGUAGED), by.x = 'val', by.y = 'LANGUAGED') %>%
  # Change to lowercase
  mutate(lbl = tolower(lbl)) %>%
  # Rename column
  rename(langd.lbl = lbl) %>%
  # Do some label editing
  # (could be done more neatly, but it's only done once so I don't care that much)
  mutate(
    # First, get rid of n.s. and etc.
    langd.lbl = gsub('(\\,\\s)?etc\\.', '', langd.lbl),
    langd.lbl = gsub('(\\,\\s)?n\\.s\\.', '', langd.lbl),
    # langd.lbl = gsub('(\\s)?n\\.e\\.c\\.', '', langd.lbl),
    # Now, rm hyphens
    langd.lbl = gsub('\\-', '', langd.lbl),
    # Remove 'languages'
    langd.lbl = gsub('\\s?languages', '', langd.lbl),
    # Remove 'and related' (probably only appears for hindi)
    langd.lbl = gsub('\\s?and\\srelated', '', langd.lbl),
    # Remove parentheticals
    langd.lbl = gsub('\\s?\\(.*\\)', '', langd.lbl),
    # Athapascan in this table, "Athabascan" in the other
    langd.lbl = gsub('athapascan', 'athabascan', langd.lbl),
    # 'French or Haitian Creole' to 'haitian'
    langd.lbl = gsub('.*(haitian).*', 'haitian', langd.lbl),
    # 'Gujarathi' to 'gujarathi'
    langd.lbl = gsub('gujarathi', 'gujarati', langd.lbl),
    # 'laotian' to 'lao'
    langd.lbl = gsub('laotian', 'lao', langd.lbl),
    # sebuano to cebuano
    langd.lbl = gsub('sebuano', 'cebuano', langd.lbl),
    # trukese to chuukese
    langd.lbl = gsub('trukese', 'chuukese', langd.lbl),
    # nigercongo
    langd.lbl = gsub('.*(nigercongo).*', '\\1', langd.lbl)
  ) %>%
  # Create new rows for every row with multiple comma-separated languages
  separate_longer_delim(col = langd.lbl, delim = ', ')


# Trim down the PRC crosswalk down to fewer columns and do minor formatting
prc.langs = oha.langx %>%
  select(lf_label, lanp16_label, langoha, langohastr) %>%
  mutate(
    # Set langohastr to only first three characters (some have blank space or text after)
    langohastr = gsub('^([a-z]{3}).*', '\\1', langohastr),
    # Remove hyphens
    across(c(lf_label, lanp16_label), ~ gsub('\\-', '', tolower(.))),
    # Remove 'languages' from labels
    lanp16_label = gsub('(\\s)?languages', '', lanp16_label),
    # Change 'jamaican creole english' to 'jamaican creole'
    lanp16_label = gsub('jamaican\\screole\\senglish', 'jamaican creole', lanp16_label),
    # Change 'swiss german' to 'swiss'
    lanp16_label = gsub('swiss\\sgerman', 'swiss', lanp16_label),
    # Change 'pennsylvania german' to 'pennsylvania dutch' for both labels
    lf_label = ifelse(grepl('pennsylvania', lanp16_label), 'pennsylvania dutch', lf_label),
    lanp16_label = gsub('pennsylvania\\sgerman', 'pennsylvania dutch', lanp16_label),
    # Change 'cajun french' to 'cajun'
    lanp16_label = gsub('cajun\\sfrench', 'cajun', lanp16_label),
    # Change 'other bantu' to 'bantu'
    lf_label = gsub('other\\sbantu', 'bantu', lf_label),
    # Change 'n.e.c.' to 'nec'
    lanp16_label = gsub('n\\.e\\.c\\.', 'nec', lanp16_label),
    # nigercongo
    lanp16_label = gsub('.*(nigercongo).*', '\\1', lanp16_label)
  ) 

# Merge these together
# Because we are matching the lang names in the acs to two different columns,
# we'll do this in two different steps
oha.lang.xwalk = merge(
  # Merge the ACS PUMS langs with
  acs.langs,
  # the PRC/OHA languages, first by the `lf_label` column
  prc.langs %>%
    select(lf_label, langohastr) %>%
    # doing this step because some languages are slash-separated
    separate_longer_delim(cols = lf_label, delim = '/') %>%
    distinct(lf_label, langohastr),
  by.x = 'langd.lbl', by.y = 'lf_label', all.x = TRUE, all.y = FALSE
) %>%
  # Now merge by the `lanp16_label` column
  merge(
    y = prc.langs %>% distinct(lanp16_label, langohastr),
    by.x = 'langd.lbl', by.y = 'lanp16_label', all.x = TRUE, all.y = FALSE, suffixes = c('1', '2')
  ) %>%
  # Some formatting
  # Assign a single languagestr for each language (is NA if both are NA)
  mutate(langohastr = ifelse(is.na(langohastr1), langohastr2, langohastr1)) %>%
  select(-c(langohastr1, langohastr2)) %>%
  # Get rid of duplicates (sort them first so we keep non-NAs)
  arrange(val, is.na(langohastr)) %>%
  distinct(val, .keep_all = TRUE) %>%
  # Manually assign some of the remaining langauges
  mutate(
    langohastr = case_match(
      val,
      # English (not in the key for some reason)
      100 ~ 'eng',
      # Rumanian, Gaelic -> other indo-european
      c(1400, 1540) ~ 'qie',
      # Hocano and Other Malayan -> 'Ilcono, Samoan, Hawaiian, Austronesian
      c(5300, 5440) ~ 'map',
      # Other specified American Indian -> other native american
      9410 ~ 'qna',
      # Near East Arabic Dialect, Other Specified African, South/Central American Indian
      # -> unspecified/other
      c(5800, 6390, 9420, 9601) ~ 'und',
      .default = langohastr
    )
  ) %>%
  # rename (lol)
  rename(langoha = langohastr)


nrow(oha.lang.xwalk)
oha.lang.xwalk %>% filter(is.na(langoha)) # nice

rm(acs.langs, prc.langs)

# Now merge this in with the ACS PUMS
acs.pums = merge(
  acs.pums, oha.lang.xwalk %>% select(LANGUAGED = val, langoha),
  all.x = TRUE
)

nrow(acs.pums) # excellent.

### Formatting to the extra language controls
lang.extra.tab = oha.langc %>%
  separate_wider_position(stcofips, widths = c(STATE = 2, COUNTY = 3)) %>%
  mutate(across(c(STATE, COUNTY), as.numeric)) %>%
  select(STATE, COUNTY, langoha, lep, E = b, M = se) %>%
  # adjust margins (going from SE to 90% M)
  mutate(
    M = M * 1.645,
    M = ifelse(M < 13, 13, M)
  ) %>%
  # Merge in megapuma
  merge(megapumas %>% filter(time %in% 2020) %>% distinct(STATE, COUNTY, megapuma))

### Recode the serial number in the reld dataset
pums.reld = pums.reld %>%
  mutate(
    CBSERIAL = gsub('GQ', '01', serialno),
    CBSERIAL = gsub('HU', '00', CBSERIAL),
    CBSERIAL = as.numeric(CBSERIAL)
  ) %>%
  rename(PERNUM = sporder)

# -------------------------------------------------------------------
# Formulate objects for model

### Tabular data (y)

# Tabular constraints without ancestry

y.p1 = acs.tab %>%  
  # Removing the ancestry group variables
  select(-contains('ASZV')) %>%
  # Pivoting out non-geographic tabular variables
  pivot_longer(cols = -c(COUNTYA, STATEA, megapuma), names_to = 'var_name', values_to = 'value') %>%
  merge(
    rbind(
      ipums_var_info(anc.lng.tab.raw, matches('[EM]\\d{3}$')) %>% select(var_name, var_label, var_desc),
      ipums_var_info(dis.age.tab.raw, matches('[EM]\\d{3}$')) %>% select(var_name, var_label, var_desc),
      ipums_var_info(rac.eth.tab.raw, matches('[EM]\\d{3}$')) %>% select(var_name, var_label, var_desc)
    )
  ) %>%
  # Convert variable info to lowercase for easier regexing
  mutate(across(c(var_label, var_desc), tolower)) %>%
  # Split the variable name up so that we can pivot out estimates and margins
  # for same variable
  separate_wider_position(var_name, c(form = 4, me = 1, code = 3)) %>%
  mutate(
    var_label = gsub('estimates:\\s', '', var_label),
    var_label = gsub('margins\\sof\\serror\\:\\s', '', var_label),
    univ = gsub('.+universe\\:\\s(.+)\\).*', '\\1', var_desc),
    univ = gsub('\\salone.+$', '', univ)
  ) %>%
  # Get rid of unnecessary columns
  select(-c(code, var_desc)) %>%
  # Rename columns for compatibility
  rename(STATE = STATEA, COUNTY = COUNTYA) %>%
  pivot_wider(names_from = me, values_from = value)

# Tabular ancestry constraints (collapsed in a separate script)
y.p2 = ances.table %>%
  rename(
    var_label = reald.grp,
    E = estimate,
    M = mrgerror
  ) %>%
  mutate(
    var_label = tolower(var_label),
    form = 'ASZV',
    univ = 'total population'
  ) %>%
  filter(!grepl('total', var_label)) %>%
  select(names(y.p1))

# Format the extra language info
y.p3 = lang.extra.tab %>%
  mutate(
    var_label = paste(langoha, lep, sep = '_'),
    form = 'ohal',
    univ = 'total population age 5 and older'
  ) %>%
  select(names(y.p1))

# Combine and format
y = rbind(y.p1, y.p2, y.p3) %>%
  # Set any negative constraints to zero
  mutate(M = ifelse(M < 0, 0, M)) %>%
  # Get rid of duplicates
  distinct(STATE, COUNTY, var_label, univ, .keep_all = TRUE) %>%
  # Getting rid fo duplicate sex-age groupings for civilian population
  filter(!(grepl('(fe)?male\\:[^\\:]+$', var_label) & grepl('\\d', univ))) %>%
  # Start classifying variables...
  mutate(
    # making a dummy var for flagging 'total' appearing in name
    is.total = grepl('total', var_label),
    var_type = case_when(
      ### Ancestry controls
      # Ancestry groups
      form %in% 'ASZV' & !is.total ~ 'grp.ance',
      ### Language controls
      # Total in universe (individuals 5 and older)
      form %in% 'AS6E' & is.total ~ 'total.5plus',
      # Language only
      form %in% 'AS6E' & !is.total & !grepl('\\:', var_label) ~ 'grp.lang',
      # Language x proficiency
      form %in% 'AS6E' & !is.total & grepl('\\:', var_label) ~ 'grp.lang.prof',
      ### Race controls
      form %in% paste0('ASN', 4:9) ~ 'grp.race',
      ### Hispanic controls
      # Total (universe is total population so this is geography grand total)
      form %in% 'ASOB' & is.total ~ 'total',
      # Ethnicity (hispanic/nonhispanic) counts
      form %in% 'ASOB' & !is.total ~ 'grp.hisp',
      ### Disability
      # Total civilian noninstitutionalized universe
      !grepl('\\d', univ) & is.total ~ 'total.diff.univ',
      # Total civilian noninstitutionalized universe 5+
      grepl('5\\syears', univ) & is.total ~ 'total.diff.univ.5plus',
      # Total civilian noninstitutionalized universe 18+
      grepl('18\\syears', univ) & is.total ~ 'total.diff.univ.18plus',
      # Sex for total civilian noninstitutionalized universe
      grepl('(fe)?male$', var_label) & !grepl('\\d', univ) ~ 'grp.sex',
      # Sex for civilian noninstitutionalized universe age 5+
      grepl('(fe)?male$', var_label) & grepl('5', univ) ~ 'grp.sex.5plus',
      # Sex for civilian noninstitutionalized universe age 18+
      grepl('(fe)?male$', var_label) & grepl('18', univ) ~ 'grp.sex.18plus',
      # Sex-age groups
      grepl('(fe)?male\\:[^\\:]+$', var_label) ~ 'grp.sex.age',
      # Disability groups - all disability controls also have age
      grepl('hear', var_label) ~ 'grp.diff.hear',
      grepl('visi', var_label) ~ 'grp.diff.visn',
      grepl('cogn', var_label) ~ 'grp.diff.cogn',
      grepl('ambu', var_label) ~ 'grp.diff.ambu',
      grepl('self', var_label) ~ 'grp.diff.self',
      grepl('inde', var_label) ~ 'grp.diff.indp',
      # Extra language
      grepl('[a-z]{3}\\_[01]', var_label) ~ 'grp.lang.xtra',
      .default = NA
    )
  ) %>%
  mutate(
    # Format numbers in age for sorting
    var_label = gsub('[Uu]nder', '0 to', var_label),
    var_label = gsub('\\:\\s(\\d{1})\\s', ': 0\\1 ', var_label),
    # Format labels for race variables
    var_label = ifelse(var_type %in% 'grp.race', paste(var_label, univ), var_label)
  ) %>%
  # Now, sort rows (this requires pivoting)
  mutate(tf = TRUE) %>%
  pivot_wider(names_from = var_type, values_from = tf, values_fill = FALSE) %>%
  arrange(
    ### Totals
    desc(total), desc(total.5plus), 
    desc(total.diff.univ), desc(total.diff.univ.5plus), desc(total.diff.univ.18plus),
    ### Race and hispanic ethnicity
    desc(grp.race), desc(grp.hisp),
    ### Ancestry
    desc(grp.ance),
    ### Language
    desc(grp.lang), desc(grp.lang.prof),
    ### Sex and sex-age
    desc(grp.sex), desc(grp.sex.5plus), desc(grp.sex.18plus),
    desc(grp.sex.age),
    ### Disabilities
    desc(grp.diff.ambu), desc(grp.diff.cogn), desc(grp.diff.hear),
    desc(grp.diff.indp), desc(grp.diff.self), desc(grp.diff.visn),
    ### Extra language groups
    desc(grp.lang.xtra),
    ### Alphabetize labels within each group
    var_label,
    ### Alphabetize geography
    STATE, COUNTY
  ) %>%
  # Deselect some unnecessary columns
  select(-c(form, is.total)) %>%
  # Pivot back to long-form
  pivot_longer(where(is.logical), names_to = 'var_type', values_to = 'tf') %>%
  filter(tf) %>% select(-tf)

y = y %>%
  filter(
    !(var_label %in% paste(rep(c('spa', 'kor', 'ara', 'vie', 'tgl', 'chn', 'eng'), each = 2), 0:1, sep = '_'))
  )

dim(y)
y
nrow(y) / 37

# Okay, I think this is good to go.

# Give me the age cuts!
age.cuts = y %>%
  filter(var_type %in% 'grp.sex.age') %>% 
  mutate(var_label = gsub('(fe)?male\\:\\s(\\d{2}).+', '\\2', var_label)) %>%
  distinct(var_label) %>%
  pull() %>%
  as.numeric()

# # Clear some memory
# rm(ances.table, ancestrs, lang.xtra.tab, oha.langc, oha.langx, y.p1, y.p2, y.p3)
# rm(anc.lng.tab.raw, dis.age.tab.raw, hh.tab.raw, rac.eth.tab.raw)
# rm(anc.lng.pums, dis.age.pums)

### Format PUMS data (x)

x = acs.pums %>%
  # NOTE: will likely want to do a complete() in here for sorting...
  # also will want to sort here
  # variable recoding time
  mutate(
    # Language
    lang = case_match(
      # see lang12 in langx
      LANGUAGE,
      1 ~ 'speak.only.english',
      12 ~ 'spanish',
      57 ~ 'arabic',
      43 ~ 'chinese',
      11 ~ 'french.haitian.cajun',
      2:4 ~ 'german.west.germanic',
      49 ~ 'korean',
      18:26 ~ 'russian.polish.slavic',
      54 ~ 'tagalog',
      50 ~ 'vietnamese',
      0 ~ NA,
      # setdiffs here are probably not necessary but they will ease my mind
      setdiff(c(2:11, 13:32), c(2:4, 11, 18:26)) ~ 'other.indo-european',
      setdiff(40:56, c(43, 49, 50, 54)) ~ 'other.asian',
      c(33:39, 58:94, 96) ~ 'other.and.unspecified', # (note: 57 ius arabic handled above)
      # ah gotta add in some more others
      .default = NA
    ),
    # English proficiency *for those who do not have eng as first language*
    prof = case_when(
      LANGUAGE %in% 1 ~ NA,
      SPEAKENG %in% 4 ~ 0,
      SPEAKENG %in% c(1, 5:6) ~ 1,
      .default = NA
    ),
    # Ancestry (this one will be a doozy!)
    across(
      c(ANCESTR1, ANCESTR2), 
      .names = '{.col}_recode',
      ~ case_match(
        .,
        # Western European (present in b04006)
        # (including 122 German Russians in here...)
        c(1, 3, 5, 8:9, 11, 20:22, 24, 26, 32, 46, 
          49:51, 77:78, 82, 84, 88:89, 91, 97:99, 122, 183) ~ 'ReWestEur',
        # White North Americans (not REALD but still present in b04006)
        # Scots-Irish, PA Dutch, Canadian, French Canadian, Acadian/Cajun, American
        c(87, 929, 931, 935, 936, 940) ~ 'Other.northam',
        # Eastern European (present in b04006)
        c(100, 115, 120, 125, 128:129, 144, 431) ~ 'ReEastEur',
        # Slavic European (present in b04006)
        c(103, 109, 111, 130, 142, 148, 152:154, 171, 176, 178) ~ 'ReSlavic',
        # Other European (in b04006, not corresponding to reald)
        # Eastern European NEC, European
        c(190, 195) ~ 'Other.euro',
        # Caribbean (present in b04006)
        c(300:302, 308, 310, 314, 322, 335:337) ~ 'ReCaribbean',
        # Hispanic South American
        c(360, 370) ~ 'ReHispSou',
        # Other "Arab" (in b04006 but NOT consistent for reald)
        # Algerian, Libyan, North African, Saudi, Yemeni, Kurdish
        c(400, 404, 411, 427, 435, 442, 496) ~ 'Other.arab',
        # North African
        c(402, 406, 429) ~ 'ReNoAfr',
        # Middle eastern
        # (including 600 Afghans here)
        c(416:417, 419, 421, 425, 434, 465, 482, 495, 600) ~ 'ReMidEast',
        # African (in reald and in b04006)
        c(510, 529, 534, 541, 553, 564, 566, 570, 576, 587:588, 593) ~ 'ReAfrican',
        # African other (in b04006 but NOT consistent for reald)
        # e.g., because this is a catch-all it includes Eritrean (ReEthiopian)...
        # Cameroonian, Congolese, Eritrean, Gambian, Guinean, Togo, West African,
        # African, Other Subsaharan African
        c(508, 515, 523, 527, 530, 586, 595, 598:599)  ~ 'Other.african',
        # Ethiopian
        522 ~ 'ReEthiopian',
        # Somalian
        568 ~ 'ReSomalian',
        # ANZAs (in b04006 but NOT consistent for reald)
        c(800, 803) ~ 'Other.anza',
        # Other groups not present in b04006 (assigned to 'other groups')
        # Flemish, British Isles, Prussian, Sicilian, Belorussian, Cossack,
        # Bohemian, Rom, Moldov(i)an, Uzbek, Central Eur., Southern Eur., Western
        # Eur., Spanish, all Hispanic, Grenadian, St. Lucian, "Middle Eastern",
        # all non-Afghan Asians, all Pacific islanders, var. American ethnicities,
        # Mixture, Other
        c(9, 12, 40, 68, 102, 108, 112, 124, 146, 169, 181, 
          185, 187, 200:295, 329, 331, 490, 
          603:799, 808:870, 900:924, 983:995, 998) ~ 'Other.groups',
        .default = NA
      )
    ),
    # Disability variables (will need to update these soon...)
    across(
      starts_with('DIFF'), 
      ~ case_match(
        .x,
        0 ~ NA,
        1 ~ 'no.',
        2 ~ 'with.'
      )
    ),
    # Age
    age = gsub('[\\[\\)]', '', cut(AGE, c(age.cuts, Inf), right = FALSE)),
    age = gsub('^(\\d{1}),', '0\\1_', age),
    # Sex
    sex = ifelse(SEX > 1, 'female', 'male'),
    # Non-institutionalized civilian population (in disability universe)
    in.disb.univ = !OCC %in% 9800:9850 & !GQ %in% 3,
    # Hispanic 
    hisp = paste0(ifelse(HISPAN > 0, '', 'non.'), 'hispanic'),
    # Language (extra)
    langx = langoha,
    is.hh = !(GQ %in% 3:4)
  ) %>%
  # Remove unneeded columns
  select(
    -c(
      ANCESTR1, ANCESTR1D, ANCESTR2, ANCESTR2D, 
      LANGUAGE, LANGUAGED, SPEAKENG, langoha, OCC, GQ,
      STATEFIP, PUMA, RACNUM, DIFFSENS,
    )
  ) %>%
  ### Get ancestry group counts
  # this step is heinously slow, probably not programmed super well...
  # Pivot out to get ancestry and counts in two columns
  pivot_longer(cols = contains('recode'), names_to = 'a12', values_to = 'ancestry') %>%
  # add a count for how many times each ancestry group is recorded for each respondent
  group_by(CBSERIAL, PERNUM, ancestry) %>%
  add_count(name = 'n.ancestry') %>%
  # drop a12 because col it is unnecessary
  select(-a12) %>%
  # distinct will get rid of duplicates
  distinct(.keep_all = TRUE) %>%
  # Now, make some edits to the ancestry 
  group_by(CBSERIAL, PERNUM) %>%
  mutate(
    n.ancestry = case_when(
      # Where there are NAs and non-NA ancestry counts, switch NA = 1 to NA = 0
      is.na(ancestry) & any(!is.na(ancestry)) ~ 0,
      # Where there are 2 NAs (i.e., no other ancestry counts) switch from NA = 2 to NA = 1
      is.na(ancestry) & !any(!is.na(ancestry)) ~ 1,
      .default = n.ancestry
    )
  ) %>%
  ungroup() %>%
  # Filtering out individuals with extraneous ancestry (NA = 0 where other
  # ancestry is assigned, see above)
  filter(n.ancestry > 0) %>%
  # Add in 'unidentified' or whatever for the missing ancestries
  mutate(ancestry = ifelse(is.na(ancestry), 'unclassified', ancestry))

# Pivoting out the extra language info
# I have trouble doing this in one go so I'll do it in two steps
xlx = x %>%
  distinct(CBSERIAL, PERNUM, AGE, langx, prof) %>%
  mutate(
    langx = ifelse(langx %in% c('eng', 'spa', 'chn', 'ara', 'kor', 'vie', 'tgl'), NA, langx)
  ) %>%
  arrange(langx, prof) %>%
  # Language (expanded)
  mutate(
    # Language (expanded)
    langx.lang = langx,
    langx.prof = prof,
    langx.ones = as.numeric(!is.na(langx) & AGE > 4)
  ) %>%
  # Pivot expanded language
  pivot_wider(
    names_from = c(langx.lang, langx.prof), names_sep = '_',
    values_from = langx.ones, values_fill = 0
  ) %>%
  select(-c(contains('NA', ignore.case = FALSE), AGE))

x = x %>%
  # Okay this is unlikely to work but let's try taking out a few of the languages
  # mutate(
  #   langx = ifelse(langx %in% c('eng', 'spa', 'chn', 'ara', 'kor', 'vie', 'tgl'), NA, langx)
  # )  %>%
  # Arrange rows to alphabetize columns downstream
  complete(
    nesting(lang, prof), ancestry, hisp,
    nesting(sex, age, DIFFPHYS, DIFFCARE, DIFFREM, DIFFHEAR, DIFFMOB, DIFFEYE)
  ) %>%
  arrange(
    ancestry, hisp, lang, prof, sex, age,
    DIFFPHYS, DIFFREM, DIFFHEAR, DIFFMOB, DIFFCARE, DIFFEYE
  ) %>%
  # Make columns for pivoting
  mutate(
    ### Totals (do not get pivoted)
    # Overall total
    total = 1,
    # Total number of individuals age 5+
    total.5plus = as.numeric(AGE > 4),
    # Total in disability universe (non-institutionalized civilians)
    total.cpop  = as.numeric(in.disb.univ),
    # Total in disability universe age 5+
    total.cpop.5plus = as.numeric(in.disb.univ & AGE > 4),
    # Total in disability universe (age 18+)
    total.cpop.18plus = as.numeric(in.disb.univ & AGE > 17),
    ### Ancestry
    # (no new columns for ancestry pivoting)
    ### Race dummy groups
    # American Indian +/ Alaska Native
    rac.ain = RACAMIND - 1,
    # Asian
    rac.asn = RACASIAN - 1,
    # Black/African American
    rac.blk = RACBLK - 1,
    # Native Hawaiian/Pacific Islander
    rac.pac = RACPACIS - 1,
    # Other races
    rac.oth = RACOTHER - 1,
    # White
    rac.wht = RACWHT - 1,
    ### Hispanic yes/no
    hsp.cols = hisp,
    hsp.ones = 1,
    ### Language +/ proficiency
    # Language groups
    lang.cols = lang,
    lang.ones = as.numeric(!is.na(lang)),
    # Language x proficiency
    lang.prof.lang = lang,
    lang.prof.prof = prof,
    lang.prof.ones = as.numeric(!is.na(lang)),
    ### Disability (plus sex/age)
    # Sex for each of the civilian noninstitutionalized subcategories
    sex.cpop.ones = as.numeric(in.disb.univ),
    sex.cpop.cols = sex,
    sex.cpop.5plus.ones = as.numeric(in.disb.univ & AGE > 4),
    sex.cpop.5plus.cols = sex,
    sex.cpop.18plus.ones = as.numeric(in.disb.univ & AGE > 17),
    sex.cpop.18plus.cols = sex,
    # Sex-age
    sex.age.ones = as.numeric(in.disb.univ),
    sex.age.sex  = sex,
    sex.age.age  = age,
    # Ambulatory disability
    ambu.sex.age.disb.sex  = sex,
    ambu.sex.age.disb.age  = age,
    ambu.sex.age.disb.disb = paste0(DIFFPHYS, 'ambu.disb'),
    ambu.sex.age.disb.ones = total.cpop.5plus,
    # Cognitive disability
    cogn.sex.age.disb.sex  = sex,
    cogn.sex.age.disb.age  = age,
    cogn.sex.age.disb.disb = paste0(DIFFREM, 'cogn.disb'),
    cogn.sex.age.disb.ones = total.cpop.5plus,
    # Hearing disability
    hear.sex.age.disb.sex  = sex,
    hear.sex.age.disb.age  = age,
    hear.sex.age.disb.disb = paste0(DIFFHEAR, 'hear.disb'),
    hear.sex.age.disb.ones = total.cpop,
    # Living-independently disability
    indp.sex.age.disb.sex  = sex,
    indp.sex.age.disb.age  = age,
    indp.sex.age.disb.disb = paste0(DIFFMOB, 'indp.disb'),
    indp.sex.age.disb.ones = total.cpop.18plus,
    # Self-care disability
    self.sex.age.disb.sex  = sex,
    self.sex.age.disb.age  = age,
    self.sex.age.disb.disb = paste0(DIFFCARE, 'self.disb'),
    self.sex.age.disb.ones = total.cpop.5plus,
    # Vision disability
    visn.sex.age.disb.sex  = sex,
    visn.sex.age.disb.age  = age,
    visn.sex.age.disb.disb = paste0(DIFFEYE, 'visn.disb'),
    visn.sex.age.disb.ones = total.cpop# ,
    # # Language (expanded)
    # langx.lang = langx,
    # langx.prof = prof,
    # langx.ones = total.5plus
  ) %>%
  ### Time to pivot:
  # Pivot Hispanic ethnicity
  # (no need to pivot race - these are handled with the dummy vars above)
  pivot_wider(names_from = hsp.cols, values_from = hsp.ones, values_fill = 0) %>%
  # Pivot ancestry
  pivot_wider(names_from = ancestry, values_from = n.ancestry, values_fill = 0) %>%
  select(-contains('NA', ignore.case = FALSE)) %>%
  # Pivot language
  pivot_wider(names_from = lang.cols, values_from = lang.ones, values_fill = 0) %>%
  select(-contains('NA', ignore.case = FALSE)) %>%
  # Pivot language x proficiency
  pivot_wider(
    names_from = c(lang.prof.lang,  lang.prof.prof), names_sep = '_',
    values_from = lang.prof.ones, values_fill = 0
  ) %>%
  select(-contains('NA', ignore.case = FALSE)) %>%
  # Pivot sex
  pivot_wider(names_from = sex.cpop.cols, values_from = sex.cpop.ones, values_fill = 0) %>%
  select(-contains('NA', ignore.case = FALSE)) %>%
  # Pivot sex (civilian population 5+)
  pivot_wider(
    names_from = sex.cpop.5plus.cols, names_glue = "{.name}5plus",
    values_from = sex.cpop.5plus.ones, values_fill = 0
  ) %>%
  select(-contains('NA', ignore.case = FALSE)) %>%
  # Pivot sex (civilian population 18+)
  pivot_wider(
    names_from = sex.cpop.18plus.cols, names_glue = "{.name}18plus",
    values_from = sex.cpop.18plus.ones, values_fill = 0
  ) %>%
  select(-contains('NA', ignore.case = FALSE)) %>%
  # Pivot sex-age
  pivot_wider(names_from = c(sex.age.sex, sex.age.age), values_from = sex.age.ones, values_fill = 0) %>%
  select(-contains('NA', ignore.case = FALSE)) %>%
  # Pivot ambulatory disability
  pivot_wider(
    names_from = c(ambu.sex.age.disb.sex, ambu.sex.age.disb.age, ambu.sex.age.disb.disb), 
    names_sep = '_', values_from = ambu.sex.age.disb.ones, values_fill = 0
  ) %>%
  select(-contains('NA', ignore.case = FALSE)) %>%
  # Pivot cognitive disability
  pivot_wider(
    names_from = c(cogn.sex.age.disb.sex, cogn.sex.age.disb.age, cogn.sex.age.disb.disb), 
    names_sep = '_', values_from = cogn.sex.age.disb.ones, values_fill = 0
  ) %>%
  select(-contains('NA', ignore.case = FALSE)) %>%
  # Pivot hearing disability
  pivot_wider(
    names_from = c(hear.sex.age.disb.sex, hear.sex.age.disb.age, hear.sex.age.disb.disb), 
    names_sep = '_', values_from = hear.sex.age.disb.ones, values_fill = 0
  ) %>%
  select(-contains('NA', ignore.case = FALSE)) %>%
  # Pivot independent-living disability
  pivot_wider(
    names_from = c(indp.sex.age.disb.sex, indp.sex.age.disb.age, indp.sex.age.disb.disb), 
    names_sep = '_', values_from = indp.sex.age.disb.ones, values_fill = 0
  ) %>%
  select(-contains('NA', ignore.case = FALSE)) %>%
  # Pivot self-care disability
  pivot_wider(
    names_from = c(self.sex.age.disb.sex, self.sex.age.disb.age, self.sex.age.disb.disb), 
    names_sep = '_', values_from = self.sex.age.disb.ones, values_fill = 0
  ) %>%
  select(-contains('NA', ignore.case = FALSE)) %>%
  # Pivot vision disabiltiy
  pivot_wider(
    names_from = c(visn.sex.age.disb.sex, visn.sex.age.disb.age, visn.sex.age.disb.disb), 
    names_sep = '_', values_from = visn.sex.age.disb.ones, values_fill = 0
  ) %>%
  select(-contains('NA', ignore.case = FALSE)) %>% 
  # # Pivot expanded language
  # pivot_wider(
  #   names_from = c(langx.lang, langx.prof), names_sep = '_', 
  #   values_from = langx.ones, values_fill = 0
  # ) %>%
  # select(-contains('NA', ignore.case = FALSE)) %>% 
  # for some reason there are individuals in the PUMS age 5-17 with living alone
  # disability but the universe for this disability in the table is only ages
  # 18+...
  select(-matches('05\\_18\\_[a-z]+\\.indp', ignore.case = FALSE)) %>%
  # Get rid of dummy individuals crated by complete()
  filter(!is.na(CBSERIAL)) %>%
  # Arrange individuals by serial number
  # arrange(CBSERIAL, PERNUM) %>%
  select(CBSERIAL, PERNUM, PERWT, HHWT, megapuma, is.hh, total:last_col())

# Combine the two matrices
x = merge(x, xlx %>% select(-c(langx, prof))) %>%
  arrange(CBSERIAL, PERNUM)

names(x)[-(1:6)] %>% length()
y %>% filter(COUNTY %in% 3) %>% nrow()

data.frame(
  x = names(x)[-(1:6)],
  y = y %>% filter(COUNTY %in% 3) %>% pull(var_label)
)

# We look aligned.

# -------------------------------------------------------------------
# Perform downscaling

fit.list = map2(
  .x = split(x, ~ megapuma),
  .y = split(y, ~ megapuma),
  function(x, y) {
    
    # # # define variables
    # total universe size
    N = y %>% filter(var_type %in% 'total') %>% pull(E) %>% sum()
    # PUMS sample size
    n = nrow(x)
    # Number of counties
    J = y %>% distinct(STATE, COUNTY) %>% nrow()
    
    # # # Prepare response and margins of error
    # Response
    Y = y$E / N
    # Error matrix
    v = (y$M * n / (N^2)) %>%
      .sparseDiagonal(n = length(.)) %>% 
      as('generalMatrix')
    
    # # # Prepare PUMS data
    # Prepare X matrix
    # NOTE: NEED TO CHECK TO MAKE SURE PROPER COLUMNS ARE EXCLUDED (correct here)
    X = kronecker(t(as.matrix(x[, -(1:6)])), .sparseDiagonal(n = J)) %>%
      t() %>%
      as('dgCMatrix')
    # prior weights
    # CHECK HHWT vs. PERWT
    q = matrix(rep(x$PERWT, each = J), ncol = 1) %>% (\(m) m / sum(m))
    
    return(PMEDM_solve(X, Y, v, q, opt = list(tr_rad = 2)))
    
  }
)

### Extract constraints
con.list = map2_df(
  .x = fit.list,
  .y = split(y, ~ megapuma),
  function(out.fit, y) y %>% mutate(pred = out.fit$pred * sum(E[var_type %in% 'total']))
) 

# Plotting
con.list %>%
  ggplot(aes(x = E, y = pred)) +
  geom_point(aes(fill = var_type), shape = 21, size = 3) +
  facet_wrap(~ megapuma, scales = 'free')
# looks okay

con.list %>%
  filter(M > 0) %>%
  count(megapuma, inm = abs(E - pred) < M) %>%
  pivot_wider(names_from = inm, names_prefix = 'inm', values_from = n, values_fill = 0)
# wow!

con.list %>%
  filter(M > 0) %>%
  filter(abs(E - pred) > M) %>%
  arrange(desc(abs(E - pred) / M))

# These are missing cases (easy to handle)

con.list %>%
  filter(!M) %>%
  arrange(abs(E - pred))
# Wow, nailed it.

con.list %>%
  filter(M > 0) %>%
  group_by(megapuma) %>%
  filter(any(abs(E - pred) > M)) %>%
  group_by(megapuma, var_type) %>%
  summarise(inm = mean(abs(E - pred) < M)) %>%
  pivot_wider(names_from = megapuma, values_from = inm, values_fill = 0)

#### #### #### 
# Some data checks I did when fiddling around before
# y %>%
#   filter(var_type %in% c('total', 'grp.race')) %>%
#   group_by(megapuma, var_type) %>%
#   summarise(sume = sum(E)) %>%
#   pivot_wider(names_from = var_type, values_from = sume) %>%
#   mutate(ratio = grp.race / total)
# # Hmm... not that many more in the race-sum than the overall total
# 
# acs.pums %>%
#   group_by(megapuma) %>%
#   summarise(mrc = mean(RACNUM))
# # These numbers are pretty similar...

# -------------------------------------------------------------------
# Try aggregating to household level

### Add in occupied household + group quarters constraints

y.hh = hh.tab.raw %>%
  # Select columns
  select(STATEA, COUNTYA, matches('[A-Za-z0-9]{4}[ME]\\d{3}')) %>%
  # Change state and county codes to numeric (needed for merge)
  mutate(across(c(STATEA, COUNTYA), as.numeric)) %>%
  # remove unnecessary total housing and vacant housing cols
  select(-matches('ASS8[EM]00[13]')) %>%
  # Add in megapumas
  merge(
    y = megapumas %>% filter(time %in% 2020) %>% distinct(STATE, COUNTY, megapuma),
    by.x = c('STATEA', 'COUNTYA'), by.y = c('STATE', 'COUNTY')
  ) %>%
  pivot_longer(cols = -c(COUNTYA, STATEA, megapuma), names_to = 'var_name', values_to = 'value') %>%
  merge(
    ipums_var_info(hh.tab.raw, matches('[EM]\\d{3}$')) %>% select(var_name, var_label, var_desc)
    # rbind(
    #   ipums_var_info(hh.tab.raw, matches('[EM]\\d{3}$')) %>% select(var_name, var_label, var_desc),
    #   ipums_var_info(gq.tab.raw, matches('[EM]\\d{3}$')) %>% select(var_name, var_label, var_desc)
    # )
  ) %>%
  mutate(across(c(var_label, var_desc), tolower)) %>%
  # Split the variable name up so that we can pivot out estimates and margins
  # for same variable
  separate_wider_position(var_name, c(form = 4, me = 1, code = 3)) %>%
  mutate(
    var_label = gsub('estimates:\\s', '', var_label),
    var_label = gsub('margins\\sof\\serror\\:\\s', '', var_label),
    univ = gsub('.+universe\\:\\s(.+)\\).*', '\\1', var_desc),
    univ = gsub('\\salone.+$', '', univ)
  ) %>%
  # Get rid of unnecessary columns
  select(-c(code, var_desc, form)) %>%
  # Rename columns for compatibility
  rename(STATE = STATEA, COUNTY = COUNTYA) %>%
  pivot_wider(names_from = me, values_from = value) %>%
  arrange(var_label, STATE, COUNTY) %>%
  mutate(var_type = ifelse(var_label %in% 'occupied', 'total.hh', 'total.gq'))

# Append new tabular constraints to old
# (mutating is specifying the prior 'total' is total people)
y.hh = rbind(
  y %>% mutate(var_type = ifelse(var_type %in% 'total', 'total.people', var_type)),
  y.hh
)

nrow(y.hh) 

# This is VERY slow - takes several minutes!
x.hh = x %>%
  group_by(megapuma, CBSERIAL, HHWT, is.hh) %>%
  summarise(across(total:last_col(), sum)) %>%
  ungroup() %>%
  mutate(occu.household = as.numeric(is.hh)) %>%
  select(megapuma, CBSERIAL, HHWT, total:last_col(), occu.household)

names(x.hh)[-(1:3)]

### Let's try it...
# (note: this also is slow for some reason)
hh.fit.list = map2(
  .x = split(x.hh, ~ megapuma),
  .y = split(y.hh, ~ megapuma),
  function(x, y) {
    
    # # # define variables
    # total universe size (in this case, households)
    N = y %>% filter(var_type %in% 'total.hh') %>% pull(E) %>% sum()
    # PUMS sample size
    n = nrow(x)
    # Number of counties
    J = y %>% distinct(STATE, COUNTY) %>% nrow()
    
    # # # Prepare response and margins of error
    # Response
    Y = y$E / N
    # Error matrix
    v = (y$M * n / (N^2)) %>%
      .sparseDiagonal(n = length(.)) %>% 
      as('generalMatrix')
    
    # # # Prepare PUMS data
    # Prepare X matrix
    # NOTE: NEED TO CHECK TO MAKE SURE PROPER COLUMNS ARE EXCLUDED (correct here)
    X = kronecker(t(as.matrix(x[, -(1:3)])), .sparseDiagonal(n = J)) %>%
      t() %>%
      as('dgCMatrix')
    # prior weights
    # CHECK HHWT vs. PERWT
    q = matrix(rep(x$HHWT, each = J), ncol = 1) %>% (\(m) m / sum(m))
    
    return(PMEDM_solve(X, Y, v, q, opt = list(tr_rad = 2)))
    
  }
)

hh.con.list = map2_df(
  .x = hh.fit.list,
  .y = split(y.hh, ~ megapuma),
  function(out.fit, y) y %>% mutate(pred = out.fit$pred * sum(E[var_type %in% 'total.hh']))
) 

hh.con.list %>%
  ggplot(aes(x = E, y = pred)) +
  geom_point(aes(fill = var_type), shape = 21, size = 3) +
  facet_wrap(~ megapuma, scales = 'free')
# Holy shit...

hh.con.list %>%
  filter(M > 0) %>%
  count(megapuma, inm = abs(E - pred) < M) %>%
  pivot_wider(names_from = inm, values_from = n, names_prefix = 'inm', values_fill = 0)

hh.con.list %>%
  filter(M > 0) %>%
  count(var_type, inm = abs(E - pred) < M) %>%
  pivot_wider(names_from = inm, values_from = n, names_prefix = 'inm', values_fill = 0) %>%
  print(n = nrow(.))
# Hmm... the group quarters and household constraints are all off lol

hh.con.list %>%
  filter(var_type %in% c('total.gq', 'total.hh')) %>%
  ggplot(aes(x = E, y = pred)) +
  annotate('segment', x = 0, xend = 350000, y = 0, yend = 350000, linetype = 2) +
  geom_point(aes(fill = var_type), shape = 21, size = 3)


# -------------------------------------------------------------------
# Extract and combine allocations to records

### Get a person-based allocation

allo.person1 = map2(
  .x = split(x, ~ megapuma),
  .y = fit.list,
  .f =  function(x.data, mod.fit) {
    # x.data: ACS matrix used for extraction
    # mod.fit: model object (i.e. what is returned pmedm)
    
    matr = matrix(
      data = mod.fit$p, nrow = nrow(x.data), byrow = TRUE,
      # NOTE the year column here... maybe it would be a good idea to make a
      # flexible 'id' column
      dimnames = list(with(x.data, paste(CBSERIAL, PERNUM, sep = '_')), NULL)
    )
    
    return(matr)
  }
)

allo.person1 = map2(
  .x = allo.person1,
  .y = split(y, ~ megapuma),
  function(p.matrix, y.data) {
    # p.matrix: output from extract.fun (matrix with rows = PUMS data, cols =
    # as-yet-unlabelled tracts)
    # y.data: constraint table, with a column for tract (TRACT)
    
    # Assign tract names
    tracts = y.data %>% distinct(STATE, COUNTY) %>% unite(col = 'county') %>% pull()
    dimnames(p.matrix)[[2]] = paste(y.data$megapuma[1], tracts, sep = '_')
    
    # Normalize by population size
    pop.size = y.data %>% filter(var_type %in% 'total') %>% pull(E) %>% sum()
    p.matrix = p.matrix * pop.size
    
    # Return matrix
    return(p.matrix)
  }
)


allo.person1 = allo.person1 %>%
  lapply(
    FUN = function(m) {
      data.frame(m) %>%
        mutate(id = row.names(.)) %>%
        pivot_longer(-id, names_to = 'county', values_to = 'alloc')
    }
  ) %>%
  do.call(what = rbind) %>%
  # mutate(county = gsub('X', '', county)) %>%
  separate_wider_delim(id, delim = '_', names = c('cbserial', 'pernum')) %>%
  mutate(across(c(cbserial, pernum), as.numeric))


### Get a household-based allocation applied to people

allo.househ = map2(
  .x = split(x.hh, ~ megapuma),
  .y = hh.fit.list,
  .f =  function(x.data, mod.fit) {
    # x.data: ACS matrix used for extraction
    # mod.fit: model object (i.e. what is returned pmedm)
    
    matr = matrix(
      data = mod.fit$p, nrow = nrow(x.data), byrow = TRUE,
      # NOTE the year column here... maybe it would be a good idea to make a
      # flexible 'id' column
      dimnames = list(with(x.data, CBSERIAL), NULL)
    )
    
    return(matr)
  }
)

allo.househ = map2(
  .x = allo.househ,
  .y = split(y.hh, ~ megapuma),
  function(p.matrix, y.data) {
    # p.matrix: output from extract.fun (matrix with rows = PUMS data, cols =
    # as-yet-unlabelled tracts)
    # y.data: constraint table, with a column for tract (TRACT)
    
    # Assign tract names
    tracts = y.data %>% distinct(STATE, COUNTY) %>% unite(col = 'county') %>% pull()
    dimnames(p.matrix)[[2]] = paste(y.data$megapuma[1], tracts, sep = '_')
    
    # Normalize by population size
    pop.size = y.data %>% filter(var_type %in% 'total.hh') %>% pull(E) %>% sum()
    p.matrix = p.matrix * pop.size
    
    # Return matrix
    return(p.matrix)
  }
)

allo.househ = allo.househ %>%
  lapply(
    FUN = function(m) {
      data.frame(m) %>%
        mutate(id = row.names(.)) %>%
        pivot_longer(-id, names_to = 'county', values_to = 'alloc')
    }
  ) %>%
  do.call(what = rbind) %>%
  # mutate(county = gsub('X', '', county)) %>%
  rename(cbserial = id) %>%
  mutate(cbserial = as.numeric(cbserial))

# Oh... what if I just combined them like this?

allo.person2 = merge(
  allo.person1, allo.househ, by = c('cbserial', 'county'),
  suffixes = c('.p', '.h')
) %>%
  separate(county, into = c('megapuma', 'state', 'county'), sep = '_')

# But is there something else that needs to be done to go from household allocation to person?

allo.person2 %>%
  group_by(megapuma) %>%
  summarise(sum.p = sum(alloc.p), sum.h = sum(alloc.h)) %>%
  mutate(rdiff = sum.h - sum.p)
# Okay maximum difference is 5 (in NW!)
# Rounding error probably?
# That's very close!

# -------------------------------------------------------------------
# Extract and combine allocations to records

allo.person2 = merge(
  allo.person2, pums.reld %>% select(CBSERIAL, PERNUM, reldpri),
  by.x = c('cbserial', 'pernum'), by.y = c('CBSERIAL', 'PERNUM'),
  all.x = TRUE
) %>%
  rename(reld = reldpri)

reld.allocations = allo.person2 %>%
  group_by(state, county, reld) %>%
  summarise(across(c(alloc.p, alloc.h), sum))

reld.allocations %>%
  filter(alloc.p < 10000, alloc.h < 10000) %>%
  mutate(county = paste(state, county)) %>%
  ggplot(aes(x = alloc.p, y = alloc.h)) +
  geom_point() +
  annotate('segment', x = 0.01, y = 0.01, xend = 10000, yend = 10000, colour = 'blue', linetype = 2) # +
  # scale_x_log10() +
  # scale_y_log10()
